import requests
import re
import time
import os

# --- AYARLAR ---
BASE_URL = "https://www.atv.com.tr"

# 1. Taranacak Kategori SayfalarÄ±
DIRECTORIES = [
    {"name": "GÃ¼ncel Diziler", "url": "/diziler", "type": "DIZI"},
    {"name": "Eski Diziler", "url": "/eski-diziler", "type": "DIZI"},
    {"name": "Programlar", "url": "/programlar", "type": "PROGRAM"}
]

# 2. Manuel Eklenecek Ã–zel Haber/Program Linkleri (Slug'larÄ±)
# Bu programlar genel listelerde Ã§Ä±kmasa bile zorla eklenir.
MANUAL_SHOWS = [
    {"slug": "atv-ana-haber", "name": "ATV Ana Haber", "type": "HABER"},
    {"slug": "kahvalti-haberleri", "name": "KahvaltÄ± Haberleri", "type": "HABER"},
    {"slug": "gun-ortasi-bulteni", "name": "GÃ¼n OrtasÄ± BÃ¼lteni", "type": "HABER"},
    {"slug": "atvde-hafta-sonu", "name": "ATV'de Hafta Sonu", "type": "HABER"}
]

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Referer': 'https://www.atv.com.tr/'
}

def get_all_content():
    """TÃ¼m dizileri, programlarÄ± ve haberleri toplar"""
    content_dict = {}

    # 1. Kategori SayfalarÄ±nÄ± Tara
    for directory in DIRECTORIES:
        try:
            print(f"[{directory['name']}] SayfasÄ± taranÄ±yor...")
            r = requests.get(f"{BASE_URL}{directory['url']}", headers=HEADERS, timeout=15)
            
            # Regex ile linkleri ve resimleri bul
            pattern = r'<a href="/([^"]+)"[^>]*?class="[^"]*blankpage[^"]*"[^>]*?>.*?<img[^>]*?src="([^"]+)"[^>]*?alt="([^"]+)"'
            matches = re.findall(pattern, r.text, re.DOTALL)

            for slug, logo, name in matches:
                # Gereksizleri atla
                if any(x in slug.lower() for x in ['canli-yayin', 'fragman', 'yayin-akisi']):
                    continue
                
                # Resim URL temizle
                clean_logo = logo.split('?')[0]
                
                if slug not in content_dict:
                    content_dict[slug] = {
                        'name': name.strip(),
                        'slug': slug,
                        'logo': clean_logo,
                        'group': directory['type']
                    }
            print(f"  -> {len(matches)} iÃ§erik bulundu.")
            
        except Exception as e:
            print(f"  Hata: {e}")

    # 2. Manuel Haber BÃ¼ltenlerini Ekle
    print("[Ã–zel Haber BÃ¼ltenleri] Kontrol ediliyor...")
    for show in MANUAL_SHOWS:
        if show['slug'] not in content_dict:
            # Haberlerin logosunu manuel bulamayacaÄŸÄ±mÄ±z iÃ§in varsayÄ±lan atv logosu veya boÅŸ bÄ±rakÄ±yoruz
            # Veya o sayfanÄ±n meta taglerinden Ã§ekilebilir ama ÅŸimdilik basit tutalÄ±m.
            content_dict[show['slug']] = {
                'name': show['name'],
                'slug': show['slug'],
                'logo': "https://www.atv.com.tr/assets/img/atv-logo-meta.jpg", # VarsayÄ±lan logo
                'group': show['type']
            }
            print(f"  -> {show['name']} listeye eklendi.")

    return list(content_dict.values())

def get_episodes(series_slug, series_name):
    """Ä°Ã§eriÄŸin bÃ¶lÃ¼mlerini Ã§eker"""
    episodes = []
    
    # Haber bÃ¼ltenleri iÃ§in /bolumler sayfasÄ± genelde Ã§alÄ±ÅŸÄ±r
    bolumler_url = f"{BASE_URL}/{series_slug}/bolumler"
    
    try:
        r = requests.get(bolumler_url, headers=HEADERS, timeout=10)
        
        # 1. Dropdown YÃ¶ntemi (En saÄŸlÄ±klÄ±sÄ±)
        # <option value="/avrupa-yakasi/189-bolum/izle">
        dropdown_pattern = r'<option[^>]*value="/([^/]+)/([^"]+)"[^>]*>'
        matches = re.findall(dropdown_pattern, r.text)
        
        if matches:
            for slug, path in matches:
                if slug == series_slug and 'izle' in path:
                    full_url = f"{BASE_URL}/{slug}/{path}"
                    
                    # BÃ¶lÃ¼m adÄ±nÄ±/numarasÄ±nÄ± path'den Ã§Ä±kar
                    # Ã¶rn: 189-bolum-izle -> 189. BÃ¶lÃ¼m
                    # Ã¶rn: 2023-10-10-bolum-izle -> 2023-10-10
                    ep_name = path.replace('-izle', '').replace('-bolum', '').replace('-', ' ').title()
                    
                    # SÄ±ralama iÃ§in numara bulmaya Ã§alÄ±ÅŸ
                    ep_num = 0
                    num_match = re.search(r'^(\d+)', ep_name)
                    if num_match:
                        ep_num = int(num_match.group(1))
                    
                    episodes.append({
                        'url': full_url,
                        'name': f"{ep_name}. BÃ¶lÃ¼m" if ep_num > 0 and len(str(ep_num)) < 5 else ep_name, # Tarih ise "BÃ¶lÃ¼m" yazma
                        'order': ep_num
                    })

        # 2. EÄŸer dropdown yoksa ve bu bir DÄ°ZÄ° ise brute-force dene (Haberlerde brute-force yapÄ±lmaz)
        if not episodes and 'haber' not in series_slug:
            # (Buradaki eski brute-force mantÄ±ÄŸÄ±nÄ± kÄ±salttÄ±m, genelde dropdown Ã§alÄ±ÅŸÄ±r)
            pass
            
    except Exception as e:
        print(f"    BÃ¶lÃ¼m hatasÄ±: {e}")

    # SÄ±rala (Ters sÄ±rala ki en yeni en Ã¼stte olsun veya M3U iÃ§in dÃ¼z)
    # Genelde diziler 1'den baÅŸlar, haberler tarihe gÃ¶re.
    # Biz gelen sÄ±rayÄ± koruyalÄ±m veya numaraya gÃ¶re sÄ±ralayalÄ±m.
    episodes.sort(key=lambda x: x['order'])
    return episodes

def fix_fake_url(video_url):
    """KarmaÅŸÄ±k ATV url'lerini dÃ¼zeltir"""
    if not video_url: return None
    
    # Pattern: i.tmgrup.com.trvideo/dizi_001_...
    if 'i.tmgrup.com.trvideo/' in video_url:
        try:
            filename = video_url.split('/')[-1]
            # karadayi_008_0150.mp4 -> dizi: karadayi, bolum: 008
            match = re.match(r'([a-zA-Z0-9-]+)_(\d+)_', filename)
            if match:
                dizi = match.group(1)
                bolum = int(match.group(2))
                # GerÃ§ek CDN adresi
                real = f"https://atv-vod.ercdn.net/{dizi}/{bolum:03d}/{dizi}_{bolum:03d}.smil/playlist.m3u8"
                return real
        except:
            pass
            
    # DiÄŸer tmgrup redirectleri
    if '//i.tmgrup.com.tr/' in video_url:
        # Basit bir replace deneyelim, genelde atv-vod.ercdn.net ile deÄŸiÅŸir
        # Ancak regex daha gÃ¼venli yukarÄ±daki gibi.
        pass

    return video_url

def extract_video_url(episode_url):
    """Sayfaya gidip video linkini cÄ±mbÄ±zlar"""
    try:
        r = requests.get(episode_url, headers=HEADERS, timeout=10)
        
        # 1. JSON-LD iÃ§indeki contentUrl
        match = re.search(r'"contentUrl"\s*:\s*"([^"]+)"', r.text)
        if match:
            url = fix_fake_url(match.group(1))
            if url: return url
            
        # 2. Direkt mp4/m3u8
        patterns = [
            r'(https?://atv-vod\.ercdn\.net/[^\s"\']+\.m3u8[^\s"\']*)',
            r'src="(https?://[^"]+\.(?:mp4|m3u8)[^"]*)"',
            r'video-src="([^"]+)"'
        ]
        
        for p in patterns:
            m = re.findall(p, r.text)
            for url in m:
                if 'fragman' not in url and 'reklam' not in url:
                    fixed = fix_fake_url(url)
                    if fixed: return fixed
                    
    except:
        pass
    return None

def create_m3u(data):
    """M3U DosyasÄ± OluÅŸturur"""
    filename = "atv.m3u"
    print(f"\nðŸ“ {filename} dosyasÄ± yazÄ±lÄ±yor...")
    
    with open(filename, "w", encoding="utf-8") as f:
        f.write("#EXTM3U\n")
        
        for slug, item in data.items():
            group = item['group']
            title = item['name']
            logo = item['logo']
            
            for ep in item['episodes']:
                ep_name = ep['name']
                url = ep['url']
                
                # M3U SatÄ±rÄ±
                # Grup: ATV-DIZI veya ATV-HABER vs.
                full_title = f"{title} - {ep_name}"
                f.write(f'#EXTINF:-1 group-title="{group}" tvg-logo="{logo}",{full_title}\n')
                f.write(f'{url}\n')
    
    print("âœ… M3U TamamlandÄ±!")

def main():
    print("ðŸš€ ATV VOD Scraper BaÅŸlatÄ±ldÄ± (M3U Modu)...")
    
    all_content = get_all_content()
    final_data = {}
    
    total = len(all_content)
    for i, item in enumerate(all_content, 1):
        print(f"\n[{i}/{total}] Ä°ÅŸleniyor: {item['name']} ({item['group']})")
        
        episodes = get_episodes(item['slug'], item['name'])
        
        if episodes:
            valid_episodes = []
            print(f"  -> {len(episodes)} bÃ¶lÃ¼m bulundu, linkler Ã§Ã¶zÃ¼lÃ¼yor...")
            
            # Her bÃ¶lÃ¼mÃ¼n iÃ§ine girip video linkini al (En fazla son 20 bÃ¶lÃ¼mÃ¼ alalÄ±m ki Ã§ok sÃ¼rmesin)
            # Ä°stersen episodes[:20] yapabilirsin. Hepsini almak uzun sÃ¼rer.
            for ep in episodes: 
                video_url = extract_video_url(ep['url'])
                if video_url:
                    valid_episodes.append({
                        'name': ep['name'],
                        'url': video_url
                    })
                    print(f"    + {ep['name']} eklendi.")
                else:
                    print(f"    - {ep['name']} video bulunamadÄ±.")
                
            if valid_episodes:
                final_data[item['slug']] = {
                    'name': item['name'],
                    'group': item['group'],
                    'logo': item['logo'],
                    'episodes': valid_episodes
                }
        else:
            print("  -> BÃ¶lÃ¼m bulunamadÄ±.")

    create_m3u(final_data)

if __name__ == "__main__":
    main()
